{
  "metadata": {
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    }
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": "<p style=\"text-align:center\">\n    <a href=\"https://skills.network\" target=\"_blank\">\n    <img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/assets/logos/SN_web_lightmode.png\" width=\"300\" alt=\"Skills Network Logo\">\n    </a>\n</p>\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "# Test Environment for Generative AI classroom labs\n\nThis lab provides a test environment for the codes generated using the Generative AI classroom.\n\nFollow the instructions below to set up this environment for further use.\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "# Setup\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "### Install required libraries\n\nIn case of a requirement of installing certain python libraries for use in your task, you may do so as shown below.\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "%pip install seaborn\nimport piplite\n\nawait piplite.install(['nbformat', 'plotly'])",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 1
    },
    {
      "cell_type": "markdown",
      "source": "### Dataset URL from the GenAI lab\nUse the URL provided in the GenAI lab in the cell below. \n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "URL = \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-DA0101EN-Coursera/laptop_pricing_dataset_mod2.csv\"",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 2
    },
    {
      "cell_type": "markdown",
      "source": "### Downloading the dataset\n\nExecute the following code to download the dataset in to the interface.\n\n> Please note that this step is essential in JupyterLite. If you are using a downloaded version of this notebook and running it on JupyterLabs, then you can skip this step and directly use the URL in pandas.read_csv() function to read the dataset as a dataframe\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "from pyodide.http import pyfetch\n\nasync def download(url, filename):\n    response = await pyfetch(url)\n    if response.status == 200:\n        with open(filename, \"wb\") as f:\n            f.write(await response.bytes())\n\npath = URL\n\nawait download(path, \"dataset.csv\")",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 3
    },
    {
      "cell_type": "markdown",
      "source": "---\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "# Test Environment\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "## Building the prompt: Importing data set\n# PROMPT 1: Write a Python code that can perform the following tasks.\n# Read the CSV file, located on a given file path, into a pandas data frame, assuming that the first row of the file can be used as the headers for the data.\n\n# Import the pandas library\nimport pandas as pd\n\n# Read the CSV file into a DataFrame\n# The header parameter is set to 0, meaning the first row will be taken as column headers\ndf = pd.read_csv(\"dataset.csv\", header=0)\n\n# To verify, let's print the DataFrame\nprint(df.head())\n\n# Get Nan info:\ndf.info()\n\n## Linear regression in one variable\n# PROMPT 2: Write a Python code that performs the following tasks.\n# 1. Develops and trains a linear regression model that uses one attribute of a data frame as the source variable and another as a target variable.\n# 2. Calculate and display the MSE and R^2 values for the trained model\n\n# Import necessary libraries\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error, r2_score\n\n# Define feature (X) and target (y)\nX = df[['CPU_frequency']]\ny = df['Price']\n\n# Split the data into training and test sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Create and train the Linear Regression model\nmodel_1 = LinearRegression()\nmodel_1.fit(X_train, y_train)\n\n# Predict on the test set\ny_pred_1 = model_1.predict(X_test)\n\n# Calculate and print Mean Squared Error (MSE)\nmse = mean_squared_error(y_test, y_pred_1)\nprint(f'Mean Squared Error for the model with 1 feature: {mse}')\n\n# Calculate and print R^2 (coefficient of determination)\nr2 = r2_score(y_test, y_pred_1)\nprint(f'R^2 Score for the model with 1 feature: {r2}')\n\n## Linear regression in multiple variables\n# PROMPT 3: Write a Python code that performs the following tasks.\n# 1. Develops and trains a linear regression model that uses some attributes of a data frame as the source variables and one of the attributes as a target variable.\n# 2. Calculate and display the MSE and R^2 values for the trained model.\n\n# Define the features (X) and target (y)\nX = df[['CPU_frequency', 'RAM_GB', 'Storage_GB_SSD', 'CPU_core', 'OS', 'GPU', 'Category']]\ny = df['Price']\n\n# Split the data into training and test sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Create and train the Linear Regression model\nmodel_2 = LinearRegression()\nmodel_2.fit(X_train, y_train)\n\n# Predict on the test set\ny_pred_2 = model_2.predict(X_test)\n\n# Calculate and print Mean Squared Error (MSE)\nmse = mean_squared_error(y_test, y_pred_2)\nprint(f'Mean Squared Error for the model with 7 features: {mse}')\n\n# Calculate and print R^2 (coefficient of determination)\nr2 = r2_score(y_test, y_pred_2)\nprint(f'R^2 Score for the model with 7 features: {r2}')\n\n## Polynomial regression\n# PROMPT 4: Write a Python code that performs the following tasks.\n# 1. Develops and trains multiple polynomial regression models, with orders 2, 3, and 5, that use one attribute of a data frame as the source variable and another as a target variable.\n# 2. Calculate and display the MSE and R^2 values for the trained models.\n# 3. Compare the performance of the models.\n\n# Import necessary libraries\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import PolynomialFeatures\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error, r2_score\n\n# Assuming the DataFrame is already generated and available\n# For demonstration, let's create a synthetic DataFrame\n\n# Define features (X) and target (y)\nX = df[['CPU_frequency']]\ny = df['Price']\n\n# Define model orders\ndegrees = [2, 3, 5]\n\n# Function to train and evaluate polynomial models\ndef evaluate_polynomial_model(degree):\n    polynomial_features = PolynomialFeatures(degree=degree)\n    X_poly = polynomial_features.fit_transform(X)\n\n    # Split the data\n    X_train, X_test, y_train, y_test = train_test_split(X_poly, y, test_size=0.2, random_state=42)\n\n    # Create and train the Polynomial Regression model\n    model_poly = LinearRegression()\n    model_poly.fit(X_train, y_train)\n\n    # Predict on the test set\n    y_pred_poly = model_poly.predict(X_test)\n\n    # Calculate and return MSE and R^2\n    mse = mean_squared_error(y_test, y_pred_poly)\n    r2 = r2_score(y_test, y_pred_poly)\n    return mse, r2\n\n# Evaluate each polynomial model\nresults = {}\nfor degree in degrees:\n    mse, r2 = evaluate_polynomial_model(degree)\n    results[f'Degree {degree}'] = {'MSE': mse, 'R^2': r2}\n\n# Display results\nfor deg, metrics in results.items():\n    print(f'{deg} Polynomial Regression Model Metrics: MSE = {metrics[\"MSE\"]:.4f}, R^2 = {metrics[\"R^2\"]:.4f}')\n\n# Compare performances\nbest_model = min(results, key=lambda x: results[x]['MSE'])\nprint(f'\\nBest Performing Polynomial Regression Model is Degree {best_model} with MSE = {results[best_model][\"MSE\"]:.4f} and R^2 = {results[best_model][\"R^2\"]:.4f}')\n\n\n## Creating a Pipeline\n# PROMPT 5: Write a Python code that performs the following tasks.\n# 1. Create a pipeline that performs parameter scaling, Polynomial Feature generation, and Linear regression. Use the set of multiple features as before to create this pipeline.\n# 2. Calculate and display the MSE and R^2 values for the trained model.\n\n# Import necessary libraries\nimport pandas as pd\nimport numpy as np\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import PolynomialFeatures\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error, r2_score\n\n# Define features and target\nX = df[['CPU_frequency', 'RAM_GB', 'Storage_GB_SSD', 'CPU_core', 'OS', 'GPU', 'Category']]\ny = df['Price']\n# Create the pipeline\npipeline = Pipeline([\n    ('scaler', StandardScaler()),  # Scale the features\n    ('poly', PolynomialFeatures(degree=2, include_bias=False)),  # Generate Polynomial Features\n    ('linear', LinearRegression())  # Use Linear Regression\n])\n\n# Split dataset into training set and test set\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Fit the pipeline on the training data\npipeline.fit(X_train, y_train)\n\n# Make predictions\ny_pred_pipe = pipeline.predict(X_test)\n\n# Calculate MSE and R^2\nmse = mean_squared_error(y_test, y_pred_pipe)\nr2 = r2_score(y_test, y_pred_pipe)\n\n# Print the results\nprint(f\"Pipeline Mean Squared Error (MSE): {mse}\")\nprint(f\"Pipeline R^2 Score: {r2}\")\n\n## Grid search and Ridge regression\n# PROMPT 6: Write a Python code that performs the following tasks.\n# 1. Use polynomial features for some of the attributes of a data frame.\n# 2. Perform Grid search on a ridge regression model for a set of values of hyperparameter alpha and polynomial features as input.\n# 3. Use cross-validation in the Grid search.\n# 4. Evaluate the resulting model's MSE and R^2 values.\n# Set of values for alpha: 0.0001,0.001,0.01, 0.1, 1, 10\n# Cross Validation: 4-fold\n# Polynomial Feature order: 2\n\n# Import necessary libraries\nimport pandas as pd\nimport numpy as np\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import PolynomialFeatures\nfrom sklearn.linear_model import Ridge\nfrom sklearn.model_selection import GridSearchCV, train_test_split\nfrom sklearn.metrics import mean_squared_error, r2_score\n\n# Define features and target\nX = df[['CPU_frequency', 'RAM_GB', 'Storage_GB_SSD', 'CPU_core', 'OS', 'GPU', 'Category']]\ny = df['Price']\n\n# Specify the pipeline stages\npoly = PolynomialFeatures(degree=2, include_bias=False)  # Create quadratic features\nridge = Ridge()\n\npipeline = Pipeline([\n    ('poly', poly),\n    ('ridge', ridge)\n])\n\n# Define the parameter grid for GridSearchCV\nparam_grid = {\n    'ridge__alpha': [0.0001,0.001,0.01, 0.1, 1, 10]  # Alpha values ranging over 4 orders of magnitude\n}\n\n# Set up GridSearchCV with 5-fold cross-validation\ngrid_search = GridSearchCV(estimator=pipeline, param_grid=param_grid, cv=4)\n\n# Split the dataset into training and test sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Run Grid Search\ngrid_search.fit(X_train, y_train)\n\n# Access the best model\nbest_model = grid_search.best_estimator_\n\n# Predict on the test set\ny_pred = best_model.predict(X_test)\n\n# Calculate MSE and R^2 of the best model\nmse = mean_squared_error(y_test, y_pred)\nr2 = r2_score(y_test, y_pred)\n\n# Print out results\nprint(f\"Best Alpha: {grid_search.best_params_['ridge__alpha']}\")\nprint(f\"Mean Squared Error (MSE): {mse}\")\nprint(f\"R^2 Score: {r2}\")\n\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "   Unnamed: 0.1  Unnamed: 0 Manufacturer  Category  GPU  OS  CPU_core  \\\n0             0           0         Acer         4    2   1         5   \n1             1           1         Dell         3    1   1         3   \n2             2           2         Dell         3    1   1         7   \n3             3           3         Dell         4    2   1         5   \n4             4           4           HP         4    2   1         7   \n\n   Screen_Size_inch  CPU_frequency  RAM_GB  Storage_GB_SSD  Weight_pounds  \\\n0              14.0       0.551724       8             256        3.52800   \n1              15.6       0.689655       4             256        4.85100   \n2              15.6       0.931034       8             256        4.85100   \n3              13.3       0.551724       8             128        2.69010   \n4              15.6       0.620690       8             256        4.21155   \n\n   Price Price-binned  Screen-Full_HD  Screen-IPS_panel  \n0    978          Low               0                 1  \n1    634          Low               1                 0  \n2    946          Low               1                 0  \n3   1244          Low               0                 1  \n4    837          Low               1                 0  \n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 238 entries, 0 to 237\nData columns (total 16 columns):\n #   Column            Non-Null Count  Dtype  \n---  ------            --------------  -----  \n 0   Unnamed: 0.1      238 non-null    int64  \n 1   Unnamed: 0        238 non-null    int64  \n 2   Manufacturer      238 non-null    object \n 3   Category          238 non-null    int64  \n 4   GPU               238 non-null    int64  \n 5   OS                238 non-null    int64  \n 6   CPU_core          238 non-null    int64  \n 7   Screen_Size_inch  238 non-null    float64\n 8   CPU_frequency     238 non-null    float64\n 9   RAM_GB            238 non-null    int64  \n 10  Storage_GB_SSD    238 non-null    int64  \n 11  Weight_pounds     238 non-null    float64\n 12  Price             238 non-null    int64  \n 13  Price-binned      238 non-null    object \n 14  Screen-Full_HD    238 non-null    int64  \n 15  Screen-IPS_panel  238 non-null    int64  \ndtypes: float64(3), int64(11), object(2)\nmemory usage: 28.0+ KB\nMean Squared Error for the model with 1 feature: 239035.99429436037\nR^2 Score for the model with 1 feature: -0.03719417833496452\nMean Squared Error for the model with 7 features: 168575.62043820194\nR^2 Score for the model with 7 features: 0.268538394630248\nDegree 2 Polynomial Regression Model Metrics: MSE = 196263.5615, R^2 = 0.1484\nDegree 3 Polynomial Regression Model Metrics: MSE = 205918.0302, R^2 = 0.1065\nDegree 5 Polynomial Regression Model Metrics: MSE = 207335.7036, R^2 = 0.1004\n\nBest Performing Polynomial Regression Model is Degree Degree 2 with MSE = 196263.5615 and R^2 = 0.1484\nPipeline Mean Squared Error (MSE): 2.791757238926465e+30\nPipeline R^2 Score: -1.211363319606691e+25\nBest Alpha: 10\nMean Squared Error (MSE): 240003.5674572627\nR^2 Score: -0.0413925470979537\n",
          "output_type": "stream"
        }
      ],
      "execution_count": 17
    },
    {
      "cell_type": "markdown",
      "source": "## Authors\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "[Abhishek Gagneja](https://www.linkedin.com/in/abhishek-gagneja-23051987/)\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "## Change Log\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "|Date (YYYY-MM-DD)|Version|Changed By|Change Description|\n|-|-|-|-|\n|2023-12-10|0.1|Abhishek Gagneja|Initial Draft created|\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Copyright © 2023 IBM Corporation. All rights reserved.\n",
      "metadata": {}
    }
  ]
}